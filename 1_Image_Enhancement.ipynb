{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Stage 1: Image Enhancement for Eye Disease Classification\n",
                "\n",
                "## Innovation Feature 2: Specialized Preprocessing\n",
                "\n",
                "This notebook implements:\n",
                "- **CLAHE (Contrast Limited Adaptive Histogram Equalization)**: Enhances blood vessels and lesions\n",
                "- **Ben Graham's Preprocessing**: Color normalization and automatic margin cropping\n",
                "\n",
                "**Expected Output**: Enhanced dataset ready for model training in Stage 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install required libraries (Colab-specific)\n",
                "!pip install opencv-python-headless scikit-image -q"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import libraries\n",
                "import cv2\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import os\n",
                "from glob import glob\n",
                "from tqdm import tqdm\n",
                "import zipfile\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Extract Dataset from Archive\n",
                "\n",
                "Upload your `archive.zip` file to Colab, then run this cell."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract archive\n",
                "archive_path = 'archive.zip'  # Update if your zip has a different name\n",
                "extract_path = 'dataset'\n",
                "\n",
                "if os.path.exists(archive_path):\n",
                "    print('Extracting archive...')\n",
                "    with zipfile.ZipFile(archive_path, 'r') as zip_ref:\n",
                "        zip_ref.extractall(extract_path)\n",
                "    print(f'Extracted to {extract_path}/')\n",
                "else:\n",
                "    print('Please upload archive.zip to Colab first!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Find dataset structure\n",
                "dataset_root = extract_path\n",
                "print('Dataset structure:')\n",
                "for root, dirs, files in os.walk(dataset_root):\n",
                "    level = root.replace(dataset_root, '').count(os.sep)\n",
                "    indent = ' ' * 2 * level\n",
                "    print(f'{indent}{os.path.basename(root)}/')\n",
                "    if level < 2:  # Only show 2 levels deep\n",
                "        subindent = ' ' * 2 * (level + 1)\n",
                "        for file in files[:3]:  # Show only first 3 files\n",
                "            print(f'{subindent}{file}')\n",
                "        if len(files) > 3:\n",
                "            print(f'{subindent}... and {len(files)-3} more files')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Preprocessing Functions\n",
                "\n",
                "### CLAHE + Ben Graham's Method"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def crop_black_margins(image, threshold=10):\n",
                "    \"\"\"Remove black margins from fundus images\"\"\"\n",
                "    # Convert to grayscale\n",
                "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
                "    \n",
                "    # Find non-black pixels\n",
                "    coords = cv2.findNonZero((gray > threshold).astype(np.uint8))\n",
                "    \n",
                "    if coords is not None:\n",
                "        x, y, w, h = cv2.boundingRect(coords)\n",
                "        cropped = image[y:y+h, x:x+w]\n",
                "        return cropped\n",
                "    return image\n",
                "\n",
                "def ben_graham_preprocessing(image, target_size=512):\n",
                "    \"\"\"\n",
                "    Ben Graham's preprocessing:\n",
                "    1. Crop black margins\n",
                "    2. Resize to target size\n",
                "    3. Color normalization (subtract local average)\n",
                "    4. Gaussian filtering\n",
                "    \"\"\"\n",
                "    # Step 1: Crop black margins\n",
                "    image = crop_black_margins(image)\n",
                "    \n",
                "    # Step 2: Resize to consistent size\n",
                "    image = cv2.resize(image, (target_size, target_size))\n",
                "    \n",
                "    # Step 3: Color normalization - subtract local average color\n",
                "    # This helps standardize lighting conditions\n",
                "    image = image.astype(np.float32)\n",
                "    \n",
                "    # Calculate local average using Gaussian blur\n",
                "    local_avg = cv2.GaussianBlur(image, (0, 0), target_size/30)\n",
                "    \n",
                "    # Subtract local average and add 128 to center around mid-gray\n",
                "    image = image - local_avg + 128\n",
                "    \n",
                "    # Clip values to valid range\n",
                "    image = np.clip(image, 0, 255).astype(np.uint8)\n",
                "    \n",
                "    # Step 4: Apply Gaussian filter to reduce noise\n",
                "    image = cv2.GaussianBlur(image, (5, 5), 0)\n",
                "    \n",
                "    return image\n",
                "\n",
                "def apply_clahe(image):\n",
                "    \"\"\"\n",
                "    Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n",
                "    to enhance blood vessels and lesions\n",
                "    \"\"\"\n",
                "    # Convert to LAB color space\n",
                "    lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
                "    \n",
                "    # Split channels\n",
                "    l, a, b = cv2.split(lab)\n",
                "    \n",
                "    # Apply CLAHE to L channel\n",
                "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
                "    l = clahe.apply(l)\n",
                "    \n",
                "    # Merge channels\n",
                "    enhanced_lab = cv2.merge([l, a, b])\n",
                "    \n",
                "    # Convert back to BGR\n",
                "    enhanced = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
                "    \n",
                "    return enhanced\n",
                "\n",
                "def enhance_fundus_image(image_path, target_size=224):\n",
                "    \"\"\"\n",
                "    Complete enhancement pipeline:\n",
                "    1. Load image\n",
                "    2. Apply Ben Graham's preprocessing\n",
                "    3. Apply CLAHE\n",
                "    \"\"\"\n",
                "    # Load image\n",
                "    image = cv2.imread(image_path)\n",
                "    \n",
                "    if image is None:\n",
                "        return None\n",
                "    \n",
                "    # Apply Ben Graham's preprocessing\n",
                "    image = ben_graham_preprocessing(image, target_size)\n",
                "    \n",
                "    # Apply CLAHE\n",
                "    image = apply_clahe(image)\n",
                "    \n",
                "    return image"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Process Dataset\n",
                "\n",
                "**Note**: Update `dataset_folder` to match your extracted folder structure"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define paths\n",
                "dataset_folder = 'dataset/dataset'  # Update based on your structure\n",
                "output_folder = 'enhanced_dataset'\n",
                "\n",
                "# Create output directory\n",
                "os.makedirs(output_folder, exist_ok=True)\n",
                "\n",
                "# Find all image files\n",
                "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
                "all_images = []\n",
                "\n",
                "for ext in image_extensions:\n",
                "    all_images.extend(glob(os.path.join(dataset_folder, '**', ext), recursive=True))\n",
                "\n",
                "print(f'Found {len(all_images)} images')\n",
                "print(f'Sample paths: {all_images[:3]}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Process all images\n",
                "print('Processing images...')\n",
                "processed_count = 0\n",
                "failed_count = 0\n",
                "\n",
                "for img_path in tqdm(all_images):\n",
                "    try:\n",
                "        # Get relative path to preserve folder structure\n",
                "        rel_path = os.path.relpath(img_path, dataset_folder)\n",
                "        output_path = os.path.join(output_folder, rel_path)\n",
                "        \n",
                "        # Create output subdirectory if needed\n",
                "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
                "        \n",
                "        # Enhance image\n",
                "        enhanced = enhance_fundus_image(img_path, target_size=224)\n",
                "        \n",
                "        if enhanced is not None:\n",
                "            # Save enhanced image\n",
                "            cv2.imwrite(output_path, enhanced)\n",
                "            processed_count += 1\n",
                "        else:\n",
                "            failed_count += 1\n",
                "            \n",
                "    except Exception as e:\n",
                "        print(f'Error processing {img_path}: {e}')\n",
                "        failed_count += 1\n",
                "\n",
                "print(f'\\nProcessing complete!')\n",
                "print(f'Successfully processed: {processed_count}')\n",
                "print(f'Failed: {failed_count}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualization: Before vs After\n",
                "\n",
                "Let's compare original and enhanced images"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select random samples for visualization\n",
                "np.random.seed(42)\n",
                "sample_images = np.random.choice(all_images, min(6, len(all_images)), replace=False)\n",
                "\n",
                "fig, axes = plt.subplots(len(sample_images), 2, figsize=(12, 4 * len(sample_images)))\n",
                "\n",
                "for idx, img_path in enumerate(sample_images):\n",
                "    # Load original\n",
                "    original = cv2.imread(img_path)\n",
                "    original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Load enhanced\n",
                "    rel_path = os.path.relpath(img_path, dataset_folder)\n",
                "    enhanced_path = os.path.join(output_folder, rel_path)\n",
                "    enhanced = cv2.imread(enhanced_path)\n",
                "    enhanced = cv2.cvtColor(enhanced, cv2.COLOR_BGR2RGB)\n",
                "    \n",
                "    # Plot\n",
                "    axes[idx, 0].imshow(original)\n",
                "    axes[idx, 0].set_title('Original')\n",
                "    axes[idx, 0].axis('off')\n",
                "    \n",
                "    axes[idx, 1].imshow(enhanced)\n",
                "    axes[idx, 1].set_title('Enhanced (CLAHE + Ben Graham)')\n",
                "    axes[idx, 1].axis('off')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Histogram Comparison\n",
                "\n",
                "Verify contrast enhancement through histogram analysis"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select one image for detailed analysis\n",
                "sample_img = sample_images[0]\n",
                "\n",
                "# Load original and enhanced\n",
                "original = cv2.imread(sample_img)\n",
                "rel_path = os.path.relpath(sample_img, dataset_folder)\n",
                "enhanced_path = os.path.join(output_folder, rel_path)\n",
                "enhanced = cv2.imread(enhanced_path)\n",
                "\n",
                "# Convert to grayscale for histogram\n",
                "orig_gray = cv2.cvtColor(original, cv2.COLOR_BGR2GRAY)\n",
                "enh_gray = cv2.cvtColor(enhanced, cv2.COLOR_BGR2GRAY)\n",
                "\n",
                "# Plot histograms\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
                "\n",
                "axes[0].hist(orig_gray.ravel(), bins=256, range=(0, 256), color='blue', alpha=0.7)\n",
                "axes[0].set_title('Original - Histogram')\n",
                "axes[0].set_xlabel('Pixel Intensity')\n",
                "axes[0].set_ylabel('Frequency')\n",
                "\n",
                "axes[1].hist(enh_gray.ravel(), bins=256, range=(0, 256), color='green', alpha=0.7)\n",
                "axes[1].set_title('Enhanced - Histogram')\n",
                "axes[1].set_xlabel('Pixel Intensity')\n",
                "axes[1].set_ylabel('Frequency')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()\n",
                "\n",
                "print('Notice: Enhanced histogram shows better distribution across intensity range')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Download Enhanced Dataset\n",
                "\n",
                "Compress and download for use in Stage 2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create zip file\n",
                "import shutil\n",
                "\n",
                "print('Creating zip archive...')\n",
                "shutil.make_archive('enhanced_dataset', 'zip', output_folder)\n",
                "print('Done! Download enhanced_dataset.zip from the Files panel')\n",
                "print('You will use this in Stage 2 (Hyperparameter Tuning)')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Summary\n",
                "\n",
                "âœ… **Completed:**\n",
                "- Dataset extraction\n",
                "- Ben Graham's preprocessing (color normalization + margin cropping)\n",
                "- CLAHE enhancement for better contrast\n",
                "- Visual comparison (Before/After)\n",
                "- Histogram analysis confirming improved contrast distribution\n",
                "\n",
                "**Next Step:** Use `enhanced_dataset.zip` in Stage 2 (Hyperparameter Tuning)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        },
        "colab": {
            "provenance": []
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}